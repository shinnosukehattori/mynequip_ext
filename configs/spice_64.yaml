run: [train, test]

cutoff_radius: 5.2
chemical_symbols: [H, Li, B, C, N, O, F, Na, Mg, Al, Si, P, S, Cl, K, Ca, Br, I] 
model_type_names: ${chemical_symbols}

data:
  _target_: mynequip_ext.data.datamodule.LMDBDataModule
  train_file_path: train.lmdb
  val_file_path: valid.lmdb
  test_file_path: test.lmdb
  transforms:
    - _target_: nequip.data.transforms.NeighborListTransform
      r_max: ${cutoff_radius}
    - _target_: nequip.data.transforms.ChemicalSpeciesToAtomTypeMapper
      chemical_symbols: ${chemical_symbols}
  seed: 123
  train_dataloader_kwargs:
    batch_size:  512
    num_workers: 4
    shuffle: true
  val_dataloader_kwargs:
    batch_size: 512
    num_workers: ${data.train_dataloader_kwargs.num_workers}
  test_dataloader_kwargs: ${data.val_dataloader_kwargs}
  stats_manager:
    _target_: nequip.data.DataStatisticsManager
    metrics:
      - field:
          _target_: nequip.data.NumNeighbors
        metric: 
          _target_: nequip.data.Mean
        name: num_neighbors_mean
      - field:
          _target_: nequip.data.PerAtomModifier
          field: total_energy
        metric:
          _target_: nequip.data.Mean
        name: per_atom_energy_mean
      - field: forces
        metric:
          _target_: nequip.data.RootMeanSquare
        per_type: true
        name: per_type_forces_rms
      - field: forces
        metric:
          _target_: nequip.data.RootMeanSquare
        name: forces_rms
      
trainer:
  _target_: lightning.Trainer

  devices: 0,1,2,3,4,5,6,7
  num_nodes: 1
  strategy: ddp

  accelerator: gpu
  enable_checkpointing: true
  max_epochs: 1500
  #max_time: 03:00:00:00
  check_val_every_n_epoch: 1
  log_every_n_steps: 50

  logger:
    _target_: lightning.pytorch.loggers.wandb.WandbLogger
    project: allegro_spice_develop2
    name: spice201_lmdb
    save_dir: ${hydra:runtime.output_dir}

  callbacks:
    - _target_: lightning.pytorch.callbacks.EarlyStopping
      monitor: val0_epoch/weighted_sum
      min_delta: 1e-3                        
      patience: 30                           

    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      monitor: val0_epoch/weighted_sum
      dirpath: ${hydra:runtime.output_dir}   
      filename: best                         
      save_last: true                        
      
    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: epoch

    - _target_: nequip.train.callbacks.NeMoExponentialMovingAverage
      decay: 0.99
      every_n_steps: 1

    # SoftAdapt scheme (https://arxiv.org/abs/2403.18122) to adaptively change loss coefficients
    #- _target_: nequip.train.callbacks.SoftAdapt
    #  beta: 1.1         # controls strength of SoftAdapt loss coefficient updates
    #  interval: epoch   # update on "epoch" or "batch" basis
    #  frequency: 5      # number of intervals (epoch or batches) between SoftAdapt loss coefficient updates

    - _target_: nequip.train.callbacks.LossCoefficientMonitor
      interval: epoch
      frequency: 5

      #- _target_: mynequip_ext.train.callbacks.GarbageCollector
      #interval: epoch
      #frequency: 1

    - _target_: nequip.train.callbacks.TestTimeXYZFileWriter
      out_file: ${hydra:runtime.output_dir}/test
      output_fields_from_original_dataset: [total_energy, forces]
      chemical_symbols: ${chemical_symbols}

  
training_module:
  _target_: nequip.train.NequIPLightningModule
  loss:
    _target_: mynequip_ext.train.MetricsManager
    metrics:
      #- name: peratomE_HL
      - name: peratomE_MSE
        field:
          _target_: nequip.data.PerAtomModifier
          field: total_energy
        coeff: 0.1
        metric:
          _target_: nequip.train.MeanSquaredError
          #_target_: nequip.train.HuberLoss
          #delta: 0.01
      #- name: force_HL
      - name: force_MSE
        field: forces
        per_type: true
        ignore_nan: true
        coeff: 0.9
        metric:
          _target_: nequip.train.MeanSquaredError
          #_target_: nequip.train.HuberLoss
          #delta: 0.01
          #- name: stress_MSE
          #field: stress
          #coeff: 0.1
          #metric:
          #_target_: nequip.train.MeanSquaredError
  train_metrics:
    _target_: mynequip_ext.train.MetricsManager
    metrics:
      - name: tE_RMSE
        field: total_energy
        coeff: 0
        metric:
          _target_: nequip.train.RootMeanSquaredError
      - name: peratomE_RMSE
        field:
          _target_: nequip.data.PerAtomModifier
          field: total_energy
        coeff: 1
        metric:
          _target_: nequip.train.RootMeanSquaredError
      - name: avgF_RMSE
        field: forces
        coeff: 0
        metric:
          _target_: nequip.train.RootMeanSquaredError
      - name: F_RMSE
        field: forces
        per_type: true
        ignore_nan: true
        coeff: 1
        metric:
          _target_: nequip.train.RootMeanSquaredError
          #- name: p_RMSE
          #field: stress
          #coeff: 1
          #metric:
          #    _target_: nequip.train.RootMeanSquaredError
  val_metrics: 
    _target_: mynequip_ext.train.MetricsManager
    metrics:
      - name: peratomE_RMSE
        field:
          _target_: nequip.data.PerAtomModifier
          field: total_energy
        coeff: 0.1
        metric:
          _target_: nequip.train.RootMeanSquaredError
      - name: F_RMSE
        field: forces
        per_type: true
        ignore_nan: true
        coeff: 0.8
        metric:
          _target_: nequip.train.RootMeanSquaredError
          #- name: p_RMSE
          #field: stress
          #coeff: 0.1
          #metric:
          #_target_: nequip.train.RootMeanSquaredError
  test_metrics: ${training_module.train_metrics}

  optimizer:
    _target_: torch.optim.Adam
    lr: 0.001
    amsgrad: false

  lr_scheduler:
    scheduler:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      factor: 0.6
      patience: 25
      min_lr: 1e-4
      threshold: 0.02
      threshold_mode: rel
    monitor: val0_epoch/weighted_sum
    interval: epoch
    frequency: 1

  model:
    _target_: allegro.model.AllegroModel
    
    # bookkeeping
    seed: 123
    model_dtype: float32
    type_names: ${model_type_names}
    #default_dtype: float64
 
    # cutoffs
    r_max: ${cutoff_radius}
 
    # radial basis
    num_bessels: 8
    bessel_trainable: true
    polynomial_cutoff_p: 6
 
    # symmetry
    l_max: 2
    parity_setting: o3_full   
    
    # Allegro layers:
    num_layers: 2
    num_tensor_features: 16
    latent_resnet: true
    
    two_body_latent_kwargs:
      mlp_latent_dimensions: [16, 32, 64]
      mlp_nonlinearity: silu
      mlp_initialization: uniform
    
    latent_kwargs:
      mlp_latent_dimensions: [64, 64]
      mlp_nonlinearity: silu
      mlp_initialization: uniform
    
    env_embed_kwargs:
      mlp_latent_dimensions: []
      mlp_nonlinearity: null
      mlp_initialization: uniform
    
    # - end allegro layers -
    
    # Final MLP to go from Allegro latent space to edge energies:
    edge_eng_kwargs:
      mlp_latent_dimensions: [64]
      mlp_nonlinearity: null
      mlp_initialization: uniform
    
    # variables derived from dataset statistics
    per_type_energy_shifts: ${training_data_stats:per_atom_energy_mean}
    per_type_energy_scales: ${training_data_stats:per_type_forces_rms}
    per_type_energy_scales_trainable: false
    per_type_energy_shifts_trainable: false
    #avg_num_neighbors: ${training_data_stats:num_neighbors_mean}
 
 
    pair_potential:
      _target_: nequip.nn.pair_potential.ZBL
      units: metal
      chemical_species: ${chemical_symbols}
      type_names: ${chemical_symbols}
  
# global options
global_options:
  seed: 123456
  allow_tf32: true

